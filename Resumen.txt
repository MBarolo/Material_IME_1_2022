A considerar para la PEP 1:

- Comentar el codigo y organizar de forma clara 
- Formular explicitamente las hipotesis nula y alternativa en lenguaje natural y matematico.
- Seleccionar adecuadamente la prueba estadistica y mencionar porque es la mas adecuada. Verificar condiciones
- Concluir adecuadamente ej: "Se falla al rechazar la hipotesis nula debido a que p > alfa mediante <prueba>, por lo que
  se puede decir que con un 95% de confianza que..."

Existen dos opciones cuando vamos a aplicar una prueba:

1 - Concluir en base a intervalos de confianza
2 - Concluir en base a prueba de hipotesis

Además debemos siempre comentar que estamos haciendo:

- ¿Que librerias es conveniente utilizar?
- ¿Que solicitan?
- Datos
- ¿Que prueba es mas adecuada?
- ¿Se cumplen las condiciones?
- ¿Cuales son las hipotesis? (Lenguaje natural y lenguaje matematico)
- ¿Cual es el procedimiento?
- ¿Que podemos concluir?

A modo de resumen es importante mencionar que hasta los contenidos vistos para la primera prueba podemos englobar todo
en dos grandes bloques:

* Pruebas parametricas: Pruebas para concluir sobre medias y proporciones

- Para medias:
	- Prueba Z: Se usa cuando la muestra tiene al menos 30 observaciones.
		    Las observaciones son independientes.
		    La poblacion sigue una distribucion normal (Grafico q-q)
	- Prueba t de student: Sirve para cualquier tamaño de muestra.
		* Una muestra
		    Las observaciones son independientes.
		    Las observaciones siguen una distribucion normal (Grafico q-q).
		* Dos muestras pareadas:
		    Se usa cuando queremos inferir sobre la diferencia de las medias (Antes-despues, Algoritmo a-Algoritmo b).
		    Cada muestra cumple las dos condiciones.
		* Dos muestras independientes:
		    La inferencia se realiza sobre la diferencia de las medias (Vacuna A-Vacuna B).
		    Cada muestra cumple las condiciones para usar la distribución t.
		    Las muestras son independientes entre sí.
- Para proporciones:
	- Prueba de Wald: Se deben cumplir dos condiciones.
		Las observaciones de la muestra son independientes.
		Se cumple la condicion exito-fracaso: np>=10 y n(1-p) >= 10.
		
		* Una proporcion: Estimador p = probabilidad de exito
		* Dos proporciones diferencia igual a 0: Estimador p = diferencia de medias 
		* Dos proporciones diferencia distinta de 0: Estimador p = diferencia de medias


* Pruebas no parametricas: Pruebas para concluir sobre proporciones
	- Chi cuadrado: homogeneidad - bondad de ajuste - independencia
	- Fisher
	- McNemar 
	- Q de Cochran 	    
	
p value y alfa: si p>alfa -> rechazar Ha
		si p< alfa ->rechazar h0
==========================================================================================================================================================
Pep 2: 

ANOVA (Muestras indep. y corr.): Utilizado para comparar medias de más de 2 grupos o muestras (Variable categórica con mas de 2 niveles)
Debe siempre realizarse un procedimiento Post Hoc al utilizar anovas, por ejemplo con tukey, esto es dado que la prueba anova (omnibus) solo determina si hay diferencia significativa en las medias de dichos grupos, no cuál es este grupo especifico que tiene esta diferencia.

Para cuando se viola la condicion de esfericidad para ANOVA de muestras correlacionadas debe utilizarse el p valor entregado por ezANOVA corregido.

Inferencia no parametrica con medianas: Ofrece alternativas para la prueba t de Student y ANOVA cuando no se cumplen las condiciones de estas.
	-Prueba de suma de rangos de Wilcoxon: Alternatva a t de Student para muestras independientes
	-Prueba de rangos con signo de WIlcoxon: Alternativa a t de Student para muestras pareadas
	
	-Prueba de Kruskal-Wallis: Alternativa a ANOVA para k>2 muestras independientes, utilizada cuando el tamaño de las muestras difieren. Al igual que con ANOVA 		debe realizarse una prueba post hoc
	-Prueba de Friedman: Alternativa a ANOVA para k>2 muestras correlacionadas
	
Remuestreo (no parametrico): Utilizada cuando se tiene que analizar parametros distintos a la media o varianza o cuando no se cumplen las condiciones de las pruebas ya conocidas.
	-Bootstrapping: Se utiliza cuando se tiene una muestra pequeña, puede utilizarse para casi cualquier estadistico.
	-Bootstrapping para dos muestras independientes: Se utiliza cuando se tiene dos muestras independientes de distinto tamaño
	-Pruebas de permutaciones: 
		-Simulacion de Monte Carlo: Es utilizada cuando la muestra es muy grande. Alternativa a F de Fisher.
Transformaciones de datos: 
	-Tukey: Es utilizada cuando la distribucion de la muestra presenta una asimetria.
	
Metodos Robustos:
	-Prueba de Yuen:alternativa a la prueba t de Student para muestras independientes cuando las varianzas de ambas muestras son muy diferentes o los tamaños de 		las muestras son muy dispares. Para pruebas unilaterales utilizar variante con bootstrapping.
	-Alternativas a ANOVA: usadas cuando los tamaños muestrales son muy diferentes o no se cumple la condición de homocedasticidad (esfericidad en el caso de grupos correlacionados)
